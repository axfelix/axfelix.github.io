# Recurse Center Blagg -- Jan 6, Day 3

OK OK OK I'm gonna do a blog! I wasn't gonnna do it because I haven't had to self-consciously adopt *blog tone* in many years now and I wasn't sure how it'd fit after all that, but I obviously did not get enough done today given **the news** and I didn't want to come to tomorrow morning's checkin with my Mets hat in my hands, so HERE I AM. Luckily I can summarize 3 days of work in what should really be a daily entry, so check me out -- working hard *and* working smart.

I wanted to make sure on Monday that I could definitely ship *something* out of the gate as I'm expecting to work with larger projects in more unfamiliar languages moving on, so I started out with something easy: a Python project discovery tool, called [putz](https://github.com/axfelix/putz). To be honest, I was committed to the name and the concept before I even looked into its viability, but to my surprise, there isn't another Python library discovery tool that exists right now, which I suspect is because PyPI is between APIs -- their documentation reflects an old XML API which is officially "throttled" but seems fully deprecated by now, and their JSON API doesn't actually do search. Luckily, there's another recent project that handles [screen-scraping](https://github.com/asadmoosvi/pypi-search) their package index, and all I had to do to make my tool was add a little bit of entropy and make sure I was adding a URL parameter to sort by "relevance" in order to avoid returning mostly abandoned projects. Pretty good! I expected that publishing to PyPI was gonna be pretty easy (as they've had malware issues in the past and don't gatekeep much, ha ha), but I'd never done it before, and knowing that I can ship a command line tool that people can install via their package managers on a few hours' notice (and which doesn't conflict with any existing CLI tools, and which doesn't require them to define third-party sources) is honestly a decent notch on my Python experience. So that was a good first day.

On Tuesday I moved on to my second project idea, making a browser extension for my 11ty/Netlify site, [Does It Beep](https://www.doesitbeep.com/). This was another "seems doable, never done it before, nice to have in the toolbox" idea, as was the site itself -- honestly, I won't be at all disappointed if I wind up having enough of these to carry me for 6 weeks -- and though I didn't get the whole thing done in one day, I did learn quite a bit. I was trying to figure out how best to consume data from a static site, and realized that it's actually pretty easy to create a JSON endpoint at an `/api` path from the same markdown data that's used to build the HTML for the site using the same Liquid/Nunjucks templates, and that it's trivially easy to enable CORS for a Netlify site by just adding a line to the config file. This is very cool! It's obviously consistent with the design and principles of static sites, but I expected they might be somehow limited in this respect, and of course they aren't. I sure do love static site generators. I also started writing the extension itself (the first commit should be [incoming](https://github.com/axfelix/doesitbeep-ext) later today or tomorrow, I don't want to spoil a particular gag just yet) and learned that it's possible to build for both Chrome and Firefox from the same codebase (I assume Mozilla had to follow Google's hegemony to facilitate this, but that seems a battle worth ceding, so good on them), so I'll be striving to do that today or tomorrow.

When I was finishing up work yesterday after throwing all of the various parts together and mostly-testing them, it struck me that my approach to js development is very poor -- I've never been a frontend developer, and once my brain starts working, I wind up sloppily copy and pasting between the Chrome dev console and my usual Sublime Text environment, which puts me well behind the best practices of the average React bootcamp graduate. So I'd really like to spend this week working on that. I also know *roughly* how webpack, etc., are supposed to work from my experience working with npm and Electron, but when I need to fetch a given js library to (e.g.) do Levenshtein fuzzy matching of text as in this case, I'm trying to actually do package management properly. So far, I have a bookmarklet to inject jQuery ... this always happens when I do frontend stuff. More soon!